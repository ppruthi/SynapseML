from pyspark.ml import Pipeline
from pyspark.ml.classification import GBTClassifier
from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder
import pyspark.sql.functions as F
from pyspark.ml.evaluation import BinaryClassificationEvaluator

from synapse.ml.explainers import ICETransformer

import matplotlib.pyplot as plt

df = spark.read.parquet("wasbs://publicwasb@mmlspark.blob.core.windows.net/AdultCensusIncome.parquet")
display(df)

categorical_features = ["race", "workclass", "marital-status", "education", "occupation", "relationship", "native-country", "sex"]
numeric_features = ["age", "education-num", "capital-gain", "capital-loss", "hours-per-week"]

string_indexer_outputs = [feature + "_idx" for feature in categorical_features]
one_hot_encoder_outputs = [feature + "_enc" for feature in categorical_features]

pipeline = Pipeline(stages=[
    StringIndexer().setInputCol("income").setOutputCol("label").setStringOrderType("alphabetAsc"),
    StringIndexer().setInputCols(categorical_features).setOutputCols(string_indexer_outputs),
    OneHotEncoder().setInputCols(string_indexer_outputs).setOutputCols(one_hot_encoder_outputs),
    VectorAssembler(inputCols=one_hot_encoder_outputs+numeric_features, outputCol="features"),
    GBTClassifier(weightCol="fnlwgt", maxDepth=7, maxIter=100)])

model = pipeline.fit(df)

data = model.transform(df)
display(data.select('income', 'probability', 'prediction'))

eval_auc = BinaryClassificationEvaluator(labelCol="label", rawPredictionCol="prediction")
eval_auc.evaluate(data)

pdp = ICETransformer(model=model, targetCol="probability", kind="average", targetClasses=[1],
                     categoricalFeatures=categorical_features, numericFeatures=numeric_features)

output_pdp = pdp.transform(df)
display(output_pdp)

# Helper functions for visualization

def get_pandas_df_from_column(df, col_name):
  keys_df = df.select(F.explode(F.map_keys(F.col(col_name)))).distinct()
  keys = list(map(lambda row: row[0], keys_df.collect()))
  key_cols = list(map(lambda f: F.col(col_name).getItem(f).alias(str(f)), keys))
  final_cols = key_cols
  pandas_df = df.select(final_cols).toPandas()
  return pandas_df

def plot_dependence_for_categorical(df, col, col_int=True, figsize=(20, 5)):
  dict_values = {}
  col_names = list(df.columns)

  for col_name in col_names:
    dict_values[col_name] = df[col_name][0].toArray()[0]
    marklist= sorted(dict_values.items(), key=lambda x: int(x[0]) if col_int else x[0]) 
    sortdict=dict(marklist)

  fig = plt.figure(figsize = figsize)
  plt.bar(sortdict.keys(), sortdict.values())

  plt.xlabel(col, size=13)
  plt.ylabel("Dependence")
  plt.show()
  
def plot_dependence_for_numeric(df, col, col_int=True, figsize=(20, 5)):
  dict_values = {}
  col_names = list(df.columns)

  for col_name in col_names:
    dict_values[col_name] = df[col_name][0].toArray()[0]
    marklist= sorted(dict_values.items(), key=lambda x: int(x[0]) if col_int else x[0]) 
    sortdict=dict(marklist)

  fig = plt.figure(figsize = figsize)

  
  plt.plot(list(sortdict.keys()), list(sortdict.values()))

  plt.xlabel(col, size=13)
  plt.ylabel("Dependence")
  plt.ylim(0.0)
  plt.show()
  

df_education_num = get_pandas_df_from_column(output_pdp, 'age_dependence')
plot_dependence_for_numeric(df_education_num, 'age')

df_occupation = get_pandas_df_from_column(output_pdp, 'marital-status_dependence')
plot_dependence_for_categorical(df_occupation, 'marital-status', False, figsize=(30, 5))

df_education_num = get_pandas_df_from_column(output_pdp, 'capital-gain_dependence')
plot_dependence_for_numeric(df_education_num, 'capital-gain_dependence')

pdp_cap_gain = ICETransformer(model=model, targetCol="probability", kind="average", targetClasses=[1], 
                              numericFeatures=[{"name": "capital-gain", "numSplits": 20, "rangeMin": 0.0,
                                                 "rangeMax": 10000.0}], numSamples=50)
output_pdp_cap_gain = pdp_cap_gain.transform(df)
df_education_num_gain = get_pandas_df_from_column(output_pdp_cap_gain, 'capital-gain_dependence')
plot_dependence_for_numeric(df_education_num_gain, 'capital-gain_dependence')

ice = ICETransformer(model=model, targetCol="probability", targetClasses=[1], 
                     categoricalFeatures=categorical_features, numericFeatures=numeric_features, numSamples=50)

output = ice.transform(df)

# Helper functions for visualization
from math import pi

from collections import defaultdict

def plot_ice_numeric(df, col, col_int=True, figsize=(20, 10)):
  dict_values = defaultdict(list)
  col_names = list(df.columns)
  num_instances = df.shape[0]
  
  instances_y = {}
  i = 0

  for col_name in col_names:
    for i in range(num_instances):
      dict_values[i].append(df[col_name][i].toArray()[0])
  
  fig = plt.figure(figsize = figsize)
  for i in range(num_instances):
    plt.plot(col_names, dict_values[i], "k")
  
  
  plt.xlabel(col, size=13)
  plt.ylabel("Dependence")
  plt.ylim(0.0)
  
  
  
def plot_ice_categorical(df, col, col_int=True, figsize=(20, 10)):
  dict_values = defaultdict(list)
  col_names = list(df.columns)
  num_instances = df.shape[0]
  
  angles = [n / float(df.shape[1]) * 2 * pi for n in range(df.shape[1])]
  angles += angles [:1]
  
  instances_y = {}
  i = 0

  for col_name in col_names:
    for i in range(num_instances):
      dict_values[i].append(df[col_name][i].toArray()[0])
  
  fig = plt.figure(figsize = figsize)
  ax = plt.subplot(111, polar=True)
  plt.xticks(angles[:-1], col_names)
  
  for i in range(num_instances):
    values = dict_values[i]
    values += values[:1]
    ax.plot(angles, values, "k")
    ax.fill(angles, values, 'teal', alpha=0.1)

  plt.xlabel(col, size=13)
  plt.show()

def overlay_ice_with_pdp(df_ice, df_pdp, col, col_int=True, figsize=(20, 5)):
  dict_values = defaultdict(list)
  col_names_ice = list(df_ice.columns)
  num_instances = df_ice.shape[0]
  
  instances_y = {}
  i = 0

  for col_name in col_names_ice:
    for i in range(num_instances):
      dict_values[i].append(df_ice[col_name][i].toArray()[0])
  
  fig = plt.figure(figsize = figsize)
  for i in range(num_instances):
    plt.plot(col_names_ice, dict_values[i], "k")
    
  dict_values_pdp = {}
  col_names = list(df_pdp.columns)

  for col_name in col_names:
    dict_values_pdp[col_name] = df_pdp[col_name][0].toArray()[0]
    marklist= sorted(dict_values_pdp.items(), key=lambda x: int(x[0]) if col_int else x[0]) 
    sortdict=dict(marklist)
  
  plt.plot(col_names_ice, list(sortdict.values()), "r", linewidth=5)
  
  
  
  plt.xlabel(col, size=13)
  plt.ylabel("Dependence")
  plt.ylim(0.0)
  plt.show()


age_df_ice = get_pandas_df_from_column(output, 'age_dependence')
age_df_pdp = get_pandas_df_from_column(output_pdp, 'age_dependence')

overlay_ice_with_pdp(age_df_ice, age_df_pdp, col='age_dependence', figsize=(30, 10))

occupation_dep = get_pandas_df_from_column(output, 'occupation_dependence')

plot_ice_categorical(occupation_dep, 'occupation_dependence', figsize=(30, 10))

pdp_based_imp = ICETransformer(model=model, targetCol="probability", kind="feature", targetClasses=[1],
                     categoricalFeatures=categorical_features, numericFeatures=numeric_features)

output_pdp_based_imp = pdp_based_imp.transform(df)
display(output_pdp_based_imp)

# Helper functions for visualization

def plot_pdp_based_imp(df, figsize=(35, 5)):
  values_list = list(df.select('pdpBasedDependence').toPandas()['pdpBasedDependence'])
  names = list(df.select('featureNames').toPandas()['featureNames'])
  dependence_values = []
  for vec in values_list:
    dependence_values.append(vec.toArray()[0])

  fig = plt.figure(figsize = figsize)
  plt.bar(names, dependence_values)

  plt.xlabel("Feature names", size=13)
  plt.ylabel("PDP-based-feature-imporance")
  plt.show()

plot_pdp_based_imp(output_pdp_based_imp)
